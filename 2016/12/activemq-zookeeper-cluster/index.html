<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1" /><meta name="baidu-site-verification" content="gDf3P6sfyW" /><meta name="360-site-verification" content="0c91ee58977e5924d92896a89289b668" /><meta name="sogou_site_verification" content="jHNtHqKt34"/><meta name="google-site-verification" content="An2eGWQakKFcIZ1YuwZSilNuSYlfHs1zH0Hr-OMW6oQ" /><title>ActiveMQ + Zookeeper 集群模式的配置整理</title><meta name="description" content=""><meta name="keywords" content="activemq,zookeeper,mq"><link rel="icon" href="/assets/favicon.ico"><link rel="apple-touch-icon" href="/assets/touch-icon.png"><link rel="stylesheet" href="/assets/core.css"><link rel="canonical" href="/2016/12/activemq-zookeeper-cluster/"><link rel="alternate" type="application/atom+xml" title="Vinny Wong's Blog" href="/feed.xml" /></head><body> <!-- search --><div class="searchform"> <label class="mk">$> </label> <input type="text" id="keyword"/> <a href="javascript:void(0);" class="clear"></a><ul class="suggest"></ul></div><script src="//lib.sinaapp.com/js/jquery/1.9.1/jquery-1.9.1.min.js"></script> <script src="/assets/main.js"></script><nav class="header-nav"> <a class="page-link" href="/">HOME</a> / <a class="page-link" href="/categories/">CATEGORY</a> / <a class="page-link" href="/feed.xml">FEED</a> / <a class="page-link" href="/about/">ABOUT</a></nav><main> <noscript><style> article .footnotes { display: block; }</style></noscript><article><div class="center"><h1>ActiveMQ + Zookeeper 集群模式的配置整理</h1><time>2016-12-25</time></div><div class="divider"></div><ul id="markdown-toc"><li><a href="#activemq--zookeeper-集群模式的配置整理" id="markdown-toc-activemq--zookeeper-集群模式的配置整理">ActiveMQ + Zookeeper 集群模式的配置整理</a><ul><li><a href="#1-介绍" id="markdown-toc-1-介绍">1. 介绍</a></li><li><a href="#2-文件准备" id="markdown-toc-2-文件准备">2. 文件准备</a></li><li><a href="#3-环境准备" id="markdown-toc-3-环境准备">3. 环境准备</a></li><li><a href="#4-开始安装" id="markdown-toc-4-开始安装">4. 开始安装</a><ul><li><a href="#41-配置jdk环境" id="markdown-toc-41-配置jdk环境">4.1 配置JDK环境</a></li><li><a href="#42-配置zookeeper集群" id="markdown-toc-42-配置zookeeper集群">4.2 配置Zookeeper集群</a></li><li><a href="#43-配置activemq集群" id="markdown-toc-43-配置activemq集群">4.3 配置ActiveMQ集群</a></li><li><a href="#44-activemq集群下的客户端连接方式" id="markdown-toc-44-activemq集群下的客户端连接方式">4.4 ActiveMQ集群下的客户端连接方式</a></li></ul></li><li><a href="#5-broker-cluster模式" id="markdown-toc-5-broker-cluster模式">5. Broker Cluster模式</a><ul><li><a href="#51-broker-cluster原理" id="markdown-toc-51-broker-cluster原理">5.1 broker-cluster原理</a></li><li><a href="#52-部署方式" id="markdown-toc-52-部署方式">5.2 部署方式</a></li></ul></li></ul></li></ul><h1 id="activemq--zookeeper-集群模式的配置整理">ActiveMQ + Zookeeper 集群模式的配置整理</h1><h2 id="1-介绍">1. 介绍</h2><p><strong><a href="http://activemq.apache.org/">ActiveMQ</a></strong>自5.9.0版本后集群的实现方式取消了传统的 <strong>master-slave</strong> 模式，取而代之的结合当下流行的<strong><a href="http://zookeeper.apache.org/">ZooKeeper</a></strong>作为裁判的选举方式。<strong>共享目录</strong>和<strong>数据库共享</strong>依然存在。</p><p>本篇文章将阐述基于<strong>zookeeper + leveldb</strong>搭建的activemq集群。</p><h2 id="2-文件准备">2. 文件准备</h2><ul><li>ActiveMQ 5.9.0 安装包，<a href="http://archive.apache.org/dist/activemq/apache-activemq/5.9.0/apache-activemq-5.9.0-bin.tar.gz">下载</a></li><li>Jdk1.8 安装包，<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">下载</a></li><li>Zookeeper 3.4.6 安装包<a href="http://www.apache.org/dyn/closer.cgi/zookeeper/">下载</a></li></ul><h2 id="3-环境准备">3. 环境准备</h2><p>服务器环境最少准备3台，本文中服务器系统为<strong>Centos7</strong>。下面是服务器地址：</p><ol><li>10.10.201.110 - <strong>Master</strong></li><li>10.10.201.111 - <strong>Slaver</strong></li><li>10.10.201.112 - <strong>Slaver</strong></li></ol><h2 id="4-开始安装">4. 开始安装</h2><p>首先把三个安装包（apache-activemq-5.9.0-bin.zip、jdk1.8.0_65.tar.gz、zookeeper-3.4.6.zip）分别上传到每个服务器中.</p><h3 id="41-配置jdk环境">4.1 配置JDK环境</h3><p><strong>ActiveMQ</strong> 和 <strong>Zookeeper</strong> 的启动都需要java环境，所以首先需要配置好JAVA_HOME。</p><p>解压缩已经上传的<code class="highlighter-rouge">jdk1.8.0_65.tar.gz</code>压缩包</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code>tar -zxvf jdk1.8.0_65.tar.gz
</code></pre></div><p>编辑<code class="highlighter-rouge">/etc/profile</code>文件，在文件结尾处添加 <strong>JAVA_HOME</strong> 环境变量并指定地址</p><div class="highlighter-rouge"><pre class="highlight"><code>export JAVA_HOME=/data/jdk1.8.0_65
export PATH=$JAVA_HOME/bin:$PATH
</code></pre></div><p>使用 <strong>source</strong> 命令使<code class="highlighter-rouge">/etc/profile</code>文件配置立即生效</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="nb">source</span> /etc/profile
</code></pre></div><p>使用 <strong>java -version</strong> 命令查看JDK是否配置成功</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code>java -version

java version <span class="s2">"1.8.0_20"</span>
Java<span class="o">(</span>TM<span class="o">)</span> SE Runtime Environment <span class="o">(</span>build 1.8.0_20-b26<span class="o">)</span>
Java HotSpot<span class="o">(</span>TM<span class="o">)</span> 64-Bit Server VM <span class="o">(</span>build 25.20-b23, mixed mode<span class="o">)</span>
</code></pre></div><p>出现上述信息则表示<strong>JDK</strong>配置已经成功，反之亦然。</p><h3 id="42-配置zookeeper集群">4.2 配置Zookeeper集群</h3><p>加压缩<code class="highlighter-rouge">zookeeper-3.4.6.zip</code>安装包</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code>unzip zookeeper-3.4.6.zip
</code></pre></div><p>编辑Zookeeper配置文件目录中的<code class="highlighter-rouge">conf/zoo.cfg</code>文件（没有就复制<code class="highlighter-rouge">zoo_sample.cfg</code>为<code class="highlighter-rouge">zoo.cfg</code>），添加如下内容</p><div class="highlighter-rouge"><pre class="highlight"><code>tickTime=2000
initLimit=10
syncLimit=5
dataDir=/var/lib/zookeeper
clientPort=2181
server.1=10.10.201.110:2888:3888
server.2=10.10.201.111:2888:3888
server.3=10.10.201.112:2888:3888
</code></pre></div><blockquote><p>将zoo.cfg文件分别拷贝到其余2个服务器中，保持3台服务器的zoo.cfg是同样的上述配置信息。</p></blockquote><p>分别在各个服务器中创建<strong>myid</strong>文件，这里注意各个IP对应的序号</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 10.10.201.110</span>
<span class="nb">echo </span>1 &gt; /var/lib/zookeeper/myid

<span class="c"># 10.10.201.111</span>
<span class="nb">echo </span>2 &gt; /var/lib/zookeeper/myid

<span class="c"># 10.10.201.112</span>
<span class="nb">echo </span>3 &gt; /var/lib/zookeeper/myid
</code></pre></div><blockquote><p>若创建myid文件失败，应该先创建<code class="highlighter-rouge">/var/lib/zookeeper</code>的目录，然后在执行上述命令，上面的命令是各自服务器执行各自的即可。</p></blockquote><p>进入<strong>zookeeper</strong>的<code class="highlighter-rouge">bin/</code>目录，执行启动命令并观察日志（3台同理）</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code>./zkServer.sh start

<span class="c"># 查看日志</span>
tail -f zookeeper.out
</code></pre></div><p>验证<strong>zookeeper</strong>的集群，在其中一台服务器中创建一条节点的数据，看看其他服务器是否能查看到同步的节点信息</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 连接进入zookeeper</span>
./zkCli.sh

<span class="c"># 创建节点数据</span>
<span class="gp">&gt; </span>create /vinny <span class="s2">"HelloWorld"</span>

<span class="c"># 在其他服务器节点中查看</span>
<span class="gp">&gt; </span>get /vinny
</code></pre></div><blockquote><p>若能在其他服务器的Zookeeper环境中查看到已创建的节点信息，则表示Zookeeper的集群搭建完成。</p></blockquote><h3 id="43-配置activemq集群">4.3 配置ActiveMQ集群</h3><p>介绍中也提到，在<strong>ActiveMQ</strong>新版中将结合<strong>Zookeeper</strong>进行集群的搭建，所以上面的操作只是为<strong>ActiveMQ</strong>集群在做准备。</p><p>解压缩<code class="highlighter-rouge">apache-activemq-5.9.0-bin.zip</code>安装包</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code>unzip apache-activemq-5.9.0-bin.zip
</code></pre></div><p>编辑<strong>ActiveMQ</strong>配置文件<code class="highlighter-rouge">conf/activemq.xml</code>，查找到<code class="highlighter-rouge">persistenceAdapter</code>节点，将原有的<strong>kahaDB</strong>存储方式注释，添加<strong>Zookeeper</strong>的持久化方式，如下：</p><div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;persistenceAdapter&gt;</span>
    <span class="c">&lt;!--&lt;kahaDB directory="${activemq.data}/kahadb"/&gt;--&gt;</span>
    <span class="nt">&lt;replicatedLevelDB</span>
            <span class="na">directory=</span><span class="s">"activemq-data"</span>
            <span class="na">replicas=</span><span class="s">"3"</span>
            <span class="na">bind=</span><span class="s">"tcp://0.0.0.0:0"</span>
            <span class="na">zkAddress=</span><span class="s">"10.10.201.110:2181,10.10.201.111:2181,10.10.201.112:2181"</span>
            <span class="na">hostname=</span><span class="s">"NGMQT01"</span>
            <span class="na">zkPath=</span><span class="s">"/activemq/leveldb-stores"</span>
    <span class="nt">/&gt;</span>
<span class="nt">&lt;/persistenceAdapter&gt;</span>
</code></pre></div><p>从上述配置文件的内容中看出，每个<strong>ActiveMQ</strong>配置都指定了<strong>Zookeeper</strong>的连接信息，并使用<code class="highlighter-rouge">zkPath</code>属性指明存储的节点名称，各个<strong>ActiveMQ</strong>抢占式的获取<code class="highlighter-rouge">/activemq/leveldb-stores</code>节点，谁抢到谁就是master。</p><p>分别启动<strong>ActiveMQ</strong>并观察日志输出（上述的配置内容其余2台都需要有同样的配置）</p><div class="language-shell highlighter-rouge"><pre class="highlight"><code><span class="c"># 启动activemq</span>
./activemq start

<span class="c"># 观察日志输出</span>
tail -f ../data/activemq.log
</code></pre></div><blockquote><p>进入<strong>Zookeeper</strong>环境中查看节点<code class="highlighter-rouge">/activemq/leveldb-stores</code>是否已经创建。</p></blockquote><p>当3台服务器中的<strong>ActiveMQ</strong>启动完成后，且输出的日志没有任何错误时，集群搭建完成。</p><blockquote><p>这里需要注意的是集群环境中的ActiveMQ，只会有一台提供服务，8161的控制界面也只会提供一个。</p></blockquote><h3 id="44-activemq集群下的客户端连接方式">4.4 ActiveMQ集群下的客户端连接方式</h3><p>客户端使用<strong>failover</strong>协议，当任何一台JMS的broker当机后，ActiveMQ能自动连接上一个可用的broker。同时会自动恢复<strong>destinations</strong>, <strong>sessions</strong>, <strong>producers</strong>和<strong>consumers</strong>。</p><p><strong>failover协议格式</strong></p><div class="highlighter-rouge"><pre class="highlight"><code>failover:(tcp://10.10.201.110:61616,tcp://10.10.201.111:61616,tcp://10.10.201.112:61616)
</code></pre></div><p><strong>传输URI选项</strong></p><p>failover协议下有很多选项可供配置，如 <strong>randomize</strong> 选项：</p><div class="highlighter-rouge"><pre class="highlight"><code>failover:(tcp://10.10.201.110:61616,tcp://10.10.201.111:61616)?randomize=false
</code></pre></div><blockquote><p>更多的URI配置选项，请参看 <a href="http://activemq.apache.org/failover-transport-reference.html">failover-transport-reference</a></p></blockquote><h2 id="5-broker-cluster模式">5. Broker Cluster模式</h2><p>上面第4章节说明了ActiveMQ的<strong>Master-slave</strong>模式，这个模式中只是避免了单点故障，服务于客户端请求的仍然只会有一台ActiveMQ的服务器。当遇到大数据量、高并发的情况下，一台ActiveMQ的服务器并不能满足需求。此时需要做负载，使并发请求均衡的分发到不同的ActiveMQ服务器中。</p><p>所以一个可靠的ActiveMQ消息模型是：<strong>Master Slave + Broker Cluster</strong></p><h3 id="51-broker-cluster原理">5.1 broker-cluster原理</h3><p>在<strong>broker-cluster</strong>模式中，每个broker通过网络互相连接，共享Queue和Topic。当<strong>broker-A</strong>中的 <em>Queue-1</em> 收到消息时，所有<strong>Consumer</strong>由于还没有处理完上一次的消息，所以此时这条消息处于<strong>pending</strong>（待处理）状态。若此时在broker-B中有<strong>Consumer</strong>在等待消费 <em>Queue-1</em> 消息时，那么broker-B会通过网络获取到broker-A中的这条消息并通知自己等待的<strong>Consumer</strong>来消费。</p><blockquote><p>这里的每个broker可以理解为第4章节的Master-Slave，也就是说一个broker就是三台ActiveMQ组成的Master-Slave模式。</p></blockquote><h3 id="52-部署方式">5.2 部署方式</h3><p><strong>broker-cluster</strong>有两种实现方式：</p><ul><li><strong>Static Broker Cluster</strong></li><li><strong>Dynamic Broker Cluster</strong></li></ul><p><strong>Static Broker Cluster配置</strong></p><div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;networkConnectors&gt;</span>
	<span class="nt">&lt;networkConnector</span> <span class="na">uri=</span><span class="s">"static:(tcp://0.0.0.0:61617)"</span> <span class="na">duplex=</span><span class="s">"false"</span><span class="nt">/&gt;</span>
<span class="nt">&lt;/networkConnectors&gt;</span>
</code></pre></div><p><strong>Dynamic Broker Cluster</strong></p><div class="language-xml highlighter-rouge"><pre class="highlight"><code><span class="nt">&lt;networkConnectors&gt;</span>
	<span class="nt">&lt;networkConnector</span> <span class="na">uri=</span><span class="s">"multicast://default"</span>
		<span class="na">dynamicOnly=</span><span class="s">"true"</span>
        <span class="na">networkTTL=</span><span class="s">"3"</span>
		<span class="na">prefetchSize=</span><span class="s">"1"</span>
		<span class="na">decreaseNetworkConsumerPriority=</span><span class="s">"true"</span> <span class="nt">/&gt;</span>
<span class="nt">&lt;/networkConnectors&gt;</span>
</code></pre></div><div class="divider"></div><blockquote id='by-nc-nd'><div> 版权所有，本作品采用<a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/">知识共享署名-非商业性使用 3.0 未本地化版本许可协议</a>进行许可。转载请注明出处：<a href="http://www.vinny.cc//2016/12/activemq-zookeeper-cluster/" akt="">http://www.vinny.cc//2016/12/activemq-zookeeper-cluster/</a></div></blockquote><div class="divider"></div><a class="w-search active" href="#" title="forward to search">⊙</a> <a class="w-catalog active" href="javascript:void(0);" title="open to catalog">≣</a></article><div class="page-navigation"> <a class="next" href="/2016/12/nginx-compile-install/" title="NEXT: 在Centos7下的nginx编译安装">&lt;&lt;</a> <span> &middot; </span> <a class="home" href="/" title="Back to Homepage">Home</a> <span> &middot; </span> <a class="prev" href="/2016/12/mongodb-replica-shard/" title="PREV: 高可用的mongodb:分片存储sharding配置">&gt;&gt;</a></div></main><div class="footer"> <!-- <span class="block">Made with &hearts; using <a href="http://jekyllrb.com/">Jekyll</a> &amp; <a href="https://github.com/heiswayi/the-plain" title="The Plain theme by Heiswayi Nrird">The Plain</a> &middot; &lt;/&gt; on <a href="https://github.com/wangjunneil" title="Hosted on GitHub">GitHub</a></span> --> <span class="block"><a href="https://vinny.cc">Vinny's Blog</a> © 2017 - All Rights Reserved</span></div></body></html>